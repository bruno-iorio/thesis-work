{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "thH7IEDfz9EJ"
   },
   "source": [
    "\n",
    "# Explanation of the task:\n",
    "\n",
    "This is the classic Emotion Recognition Classification task. Given a conversation, involving 2 or more parties, for each message/utterance, we want to predict an emotion related to it.\n",
    "\n",
    "\n",
    "Consider the example:\n",
    "\n",
    "**Person A**: \"Hello! I am very happy\" (happiness)\n",
    "\n",
    "**Person B**: \"Why? I am very angry\"   (anger)\n",
    "\n",
    "## First model idea:\n",
    "- inputs: sequence of utterances, sequence of emotions.\n",
    "- For each: Linear Layers\n",
    "- Fusion model\n",
    "\n",
    "- Loss: cross-entropy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LmXtaDwE1rk1",
    "outputId": "5b7b4576-658f-4623-dc86-bf55bca79f76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: torch in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: setuptools in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from torch) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: pandas in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: gensim in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from gensim) (7.1.0)\n",
      "Requirement already satisfied: wrapt in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from smart-open>=1.8.1->gensim) (1.17.1)\n",
      "Requirement already satisfied: datasets in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (3.2.0)\n",
      "Requirement already satisfied: filelock in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from datasets) (3.11.11)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from datasets) (0.27.1)\n",
      "Requirement already satisfied: packaging in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from aiohttp->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: matplotlib in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (3.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: tqdm in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (4.67.1)\n",
      "Requirement already satisfied: torchinfo in /home/bruno/Desktop/thesis/pt_env/lib/python3.12/site-packages (1.8.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install nltk\n",
    "! pip install torch\n",
    "! pip install pandas\n",
    "! pip install gensim\n",
    "! pip install datasets\n",
    "! pip install matplotlib\n",
    "! pip install tqdm\n",
    "! pip install torchinfo\n",
    "# eventually include tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yKzjVDPZz8Pw"
   },
   "outputs": [],
   "source": [
    "# ML resources:\n",
    "import torch\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "#others:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "punctuation = [\".\",\",\",\"?\", \"!\",\";\",\":\",\"-\",\"_\",\"(\",\")\",\"[\",\"]\",\"{\",\"}\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o85DNm0FXNeK"
   },
   "source": [
    "Here we will extract the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "KC_RQMGGXP7j"
   },
   "outputs": [],
   "source": [
    "emotions_emb = {}\n",
    "\n",
    "data = load_dataset('daily_dialog')\n",
    "X_train = data['train']['dialog']\n",
    "Y_train = data['train']['emotion']\n",
    "\n",
    "X_test = data['test']['dialog']\n",
    "Y_test = data['test']['emotion']\n",
    "\n",
    "X_val = data['validation']['dialog']\n",
    "Y_val = data['validation']['emotion']\n",
    "\n",
    "bagofwords = []\n",
    "emotions = []\n",
    "\n",
    "for lx,ly in zip(X_train,Y_train):\n",
    "  assert(len(lx) == len(ly))\n",
    "for lx,ly in zip(X_val,Y_val):\n",
    "  assert(len(lx) == len(ly))\n",
    "for lx,ly in zip(X_test,Y_test):\n",
    "  assert(len(lx) == len(ly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "euWLW7lRSZhQ"
   },
   "outputs": [],
   "source": [
    "def Preprocess_Data(X_,Y_): ## We do some simple prepocessing\n",
    "  bagofwords = []\n",
    "  emotions = []\n",
    "  X = X_\n",
    "  Y = Y_\n",
    "\n",
    "  for i in range(len(X)):\n",
    "    l1 = []\n",
    "    l2 = []\n",
    "    for j in range(len(X[i])):\n",
    "      to_append = X[i][j].lower().split()\n",
    "      l1.extend(to_append)\n",
    "      l2.extend([Y[i][j]]*len(to_append))\n",
    "      bagofwords.append(to_append)\n",
    "    X[i] = l1\n",
    "    Y[i] = l2\n",
    "\n",
    "  for i in range(len(X)): ## remove puncuation\n",
    "    to_remove = []\n",
    "    for j in range(len(X[i])):\n",
    "      if X[i][j] in punctuation:\n",
    "        to_remove.append(j)\n",
    "    for j in to_remove[::-1]:\n",
    "      X[i].pop(j)\n",
    "      Y[i].pop(j)\n",
    "  for i in Y:\n",
    "    for j in i:\n",
    "      emotions.append(j)\n",
    "  emotions = list(set(emotions))\n",
    "\n",
    "  for lx,ly in zip(X,Y):\n",
    "    assert(len(lx) == len(ly))\n",
    "  return X_, Y_, bagofwords, emotions\n",
    "\n",
    "X_train,Y_train, bagofwords1, emotions = Preprocess_Data(X_train,Y_train)\n",
    "X_test,Y_test, bagofwords2, _ = Preprocess_Data(X_test,Y_test)\n",
    "X_val,Y_val, bagofwords3, _ = Preprocess_Data(X_val,Y_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "22-jdBx2t3dm",
    "outputId": "837e932e-a01b-4e34-d477-09532fc455f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size:  11118\n",
      "test size:  1000\n",
      "validation size:  1000\n",
      "emotions:  [0, 1, 2, 3, 4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "for lx,ly in zip(X_train,Y_train):\n",
    "  assert(len(lx) == len(ly))\n",
    "for lx,ly in zip(X_val,Y_val):\n",
    "  assert(len(lx) == len(ly))\n",
    "for lx,ly in zip(X_test,Y_test):\n",
    "  assert(len(lx) == len(ly))\n",
    "\n",
    "print(\"train size: \",len(X_train))\n",
    "print(\"test size: \",len(X_test))\n",
    "print(\"validation size: \",len(X_val))\n",
    "print(\"emotions: \",emotions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "m-ZU6W8V0RZs",
    "outputId": "08d695d9-df2c-4fdc-dfe6-269aafabef31"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndata['train'] = data['train'].remove_columns(['id'])\\ndata['test'] = data['test'].remove_columns(['id'])\\ndata['validation'] = data['validation'].remove_columns(['id'])\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do that later on: So I can implement dataloaders and make the code cleaner\n",
    "\"\"\"\n",
    "data['train'] = data['train'].remove_columns(['id'])\n",
    "data['test'] = data['test'].remove_columns(['id'])\n",
    "data['validation'] = data['validation'].remove_columns(['id'])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BxOo7CsHGEIX"
   },
   "source": [
    "Now we train w2v:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZBvuQEIiGHDf",
    "outputId": "a689545b-e95c-4a02-8558-af0ca4c426b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size:  22075\n"
     ]
    }
   ],
   "source": [
    "word_dim = 100\n",
    "w2v = Word2Vec(sentences=bagofwords1, vector_size=word_dim, min_count=1)\n",
    "\n",
    "print(\"vocabulary size: \",len(w2v.wv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "6S86qh2DY_vV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4586/3779319582.py:12: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  tens = torch.from_numpy(w2v.wv[word])\n"
     ]
    }
   ],
   "source": [
    "if len(emotions_emb) > 0:\n",
    "    pass\n",
    "else:\n",
    "  emotions_emb = {}\n",
    "\n",
    "def encode_text(X):\n",
    "  train_X = []\n",
    "  words_list = []  \n",
    "  train_X_class = {}\n",
    "\n",
    "  n = 0\n",
    "  for dialog in X:\n",
    "    seq = []\n",
    "    for word in dialog:\n",
    "      if word not in words_list:\n",
    "        words_list.append(word)\n",
    "      try:\n",
    "        tens = torch.from_numpy(w2v.wv[word])\n",
    "        tens = tens.type(torch.float32)\n",
    "        seq.append(tens)\n",
    "      except:\n",
    "        tens = torch.rand(word_dim,dtype=torch.float32)\n",
    "        seq.append(tens)\n",
    "    train_X.append(seq)\n",
    "  stoi = {word:i for i,word in enumerate(words_list)}\n",
    "  itos = {i:word for i,word in enumerate(words_list)}\n",
    "\n",
    "  for i,word in itos.items():\n",
    "    tens = torch.zeros(len(words_list))\n",
    "    tens[i] = 1\n",
    "    train_X_class[i] = tens\n",
    "  return train_X, stoi, itos,train_X_class\n",
    "\n",
    "\n",
    "## We do something similar to the emotions (but we initialized them randomly)\n",
    "def encode_emotions(Y,emotions_emb):\n",
    "  train_Y = []\n",
    "  if len(emotions_emb) == 0:\n",
    "    for emotion in emotions:\n",
    "      emotions_emb[emotion] = torch.rand(word_dim,dtype=torch.float32)\n",
    "\n",
    "  for dialog in Y:\n",
    "    l = []\n",
    "    for em in dialog:\n",
    "      l.append(emotions_emb[em])\n",
    "    train_Y.append(l)\n",
    "  emotion_class = {}\n",
    "  for i in emotions:\n",
    "    ten = torch.zeros(len(emotions))\n",
    "    ten[i] = 1\n",
    "    emotion_class[i] = ten\n",
    "  Y_emo = []\n",
    "  for j in Y:\n",
    "    t = []\n",
    "    for k in j:\n",
    "      t.append(emotion_class[k])\n",
    "    Y_emo.append(t)\n",
    "  return train_Y, Y_emo, emotion_class\n",
    "\n",
    "def emotion_to_tensor(Y,emotion_class):\n",
    "  emotion_tensor = []\n",
    "  for dialog in Y:\n",
    "    l = []\n",
    "    for em in dialog:\n",
    "      l.append(emotion_class[em])\n",
    "    emotion_tensor.append(l)\n",
    "  return torch.stack(emotion_tensor)\n",
    "\n",
    "\n",
    "X_train1, stoi_train1, itos_train1, train_X_class = encode_text(X_train)\n",
    "Y_train1, Y_train_emo, emotion_class = encode_emotions(Y_train,emotions_emb)\n",
    "\n",
    "X_test1, _, _, _  = encode_text(X_test)\n",
    "Y_test1, Y_test_emo, emotion_class = encode_emotions(Y_test,emotions_emb)\n",
    "\n",
    "X_val1, _, _, _ = encode_text(X_val)\n",
    "Y_val1, Y_val_emo, _ = encode_emotions(Y_val,emotions_emb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nJCwMdlcRGBL",
    "outputId": "d7b42e32-0ffb-40dc-9360-9113901f6163"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "for l1,l2,l3 in zip(Y_train1,X_train1,Y_train_emo):\n",
    "  assert(len(l1)==len(l2) and len(l1) == len(l3))\n",
    "print(len(Y_train_emo[1]))\n",
    "print(len(Y_train1[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2pyBr61UXulR"
   },
   "source": [
    "# The model:\n",
    "## archtecture\n",
    "- 2 input channels: word encoding, emotion encoding\n",
    "- dinamically updated weights: $w_1, w_2 = w1 + w2, w1$\n",
    "### For each channel:\n",
    "   - 3 sequential Linear layers\n",
    "- fusion linear layer through concatenation\n",
    "- 2 output channels which contain a linear layer each\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "F5G-cFE81iXV"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class SimpleModel(nn.Module):\n",
    "  def __init__(self, n_emb_utt, n_emb_emo, emotions_size, vocab_size,loss_fn,device):\n",
    "    super(SimpleModel,self).__init__()\n",
    "    ## Decide size later!\n",
    "    self.loss_fn = loss_fn\n",
    "    self.target_dev = device\n",
    "    self.current_weight = 0\n",
    "    self.decoder = nn.Linear(n_emb_utt,vocab_size)\n",
    "    ## Channel for utterances/words:\n",
    "    self.Linear_utt1 = nn.Linear(n_emb_utt,40)\n",
    "    ## Channel for emotions:\n",
    "    self.Linear_emo1 = nn.Linear(n_emb_utt,40)\n",
    "    self.Linear_emo2 = nn.Linear(40,40)\n",
    "    self.Linear_emo3 = nn.Linear(40,40)\n",
    "    ## fusion by concatenation and Linear layer:\n",
    "    self.Linear_fus = nn.Linear(80,160)\n",
    "\n",
    "    ## We concatenate and do linear again (2 different concatenations)\n",
    "    self.Linear_utt_final = nn.Linear(200, n_emb_utt)\n",
    "    self.Linear_emo_final = nn.Linear(200, emotions_size)\n",
    "\n",
    "    self.softmax = nn.Softmax(dim=0)\n",
    "\n",
    "    self.Linear_hidden1 = [nn.Linear(40,40).to(device)]\n",
    "    self.Linear_hidden2 = [nn.Linear(40,40).to(device)]\n",
    "    self.Linear_hidden3 = [nn.Linear(40,40).to(device)]\n",
    "    self.Linear_hidden4 = [nn.Linear(40,40).to(device)]\n",
    "  \n",
    "  def forward_w1(self,text_emb):\n",
    "    x = self.Linear_utt1(text_emb)\n",
    "    x = self.Linear_hidden1[self.current_weight](x)\n",
    "    x = self.Linear_hidden2[self.current_weight](x)\n",
    "    return x\n",
    "\n",
    "  def forward_w2(self,emo_emb):\n",
    "    x = self.Linear_emo1(emo_emb)\n",
    "    x = self.Linear_hidden3[self.current_weight](x)\n",
    "    x = self.Linear_hidden4[self.current_weight](x)\n",
    "    return x\n",
    "\n",
    "  def forward(self, text_emb, emo_emb):\n",
    "\n",
    "    x = self.forward_w1(text_emb)\n",
    "    y = self.forward_w2(emo_emb)\n",
    "\n",
    "    z = torch.cat((x,y),-1) ## very simple\n",
    "    z = self.Linear_fus(z)\n",
    "\n",
    "    w = torch.cat((z,x),-1)\n",
    "\n",
    "    pred_token = self.Linear_utt_final(w)\n",
    "    pred_token = self.decoder(pred_token)\n",
    "    pred_token = self.softmax(pred_token)\n",
    "\n",
    "    v = torch.cat((z,y),-1)\n",
    "    v = self.Linear_emo_final(v)\n",
    "\n",
    "    pred_emotion = self.softmax(v)\n",
    "    return pred_token, pred_emotion\n",
    "\n",
    "  def predict_for_sequence(self,sequence_utt, sequence_emo):\n",
    "    pt, pe = sequence_utt[0],sequence_emo[0]\n",
    "    self.current_weight = 0\n",
    "    loss = 0\n",
    "    for j in emotions_emb.keys():\n",
    "      emotions_emb[j] = emotions_emb[j].to(self.target_dev)\n",
    "    for i in range(len(sequence_utt)):\n",
    "      pt, pe = self.forward(pt,pe)\n",
    "      pt = torch.argmax(pt).item()\n",
    "      pe = torch.argmax(pe).item()\n",
    "      if i <= len(sequence_utt)-2:\n",
    "        pt = sequence_utt[i+1]\n",
    "      else: \n",
    "        pt = itos[pt]\n",
    "      if i <= len(sequence_emo)-2:\n",
    "        pe = emotions_emb[pe] ## get embedding of emotion\n",
    "      if i < len(self.Linear_hidden1)-1:\n",
    "        self.current_weight += 1\n",
    "      else:\n",
    "        with torch.no_grad():\n",
    "          self.update_text_w()\n",
    "          self.update_emotions_w()\n",
    "          self.current_weight += 1\n",
    "    self.current_weight = 0\n",
    "    return pt, pe\n",
    "\n",
    "  def update_text_w(self):\n",
    "    with torch.no_grad():\n",
    "      new_layer1 = nn.Linear(40,40)\n",
    "      new_layer2 = nn.Linear(40,40)\n",
    "      new_weight1 = 0.2 * self.Linear_hidden1[-1].weight + 0.8 * self.Linear_hidden2[-1].weight\n",
    "      new_weight2 = self.Linear_hidden2[-1].weight.clone()\n",
    "      new_layer1.weight.copy_(new_weight1)\n",
    "      new_layer2.weight.copy_(new_weight2)\n",
    "\n",
    "      self.Linear_hidden1.append(new_layer1.to(self.target_dev))\n",
    "      self.Linear_hidden2.append(new_layer2.to(self.target_dev))\n",
    "\n",
    "  def update_emotions_w(self):\n",
    "    with torch.no_grad():\n",
    "      new_layer1 = nn.Linear(40,40)\n",
    "      new_layer2 = nn.Linear(40,40)\n",
    "      new_weight1 = 0.2 * self.Linear_hidden3[-1].weight + 0.8 * self.Linear_hidden4[-1].weight\n",
    "      new_weight2 = self.Linear_hidden3[-1].weight.clone()\n",
    "      new_layer1.weight.copy_(new_weight1)\n",
    "      new_layer2.weight.copy_(new_weight2)\n",
    "\n",
    "      self.Linear_hidden3.append(new_layer1.to(self.target_dev))\n",
    "      self.Linear_hidden4.append(new_layer2.to(self.target_dev))\n",
    "\n",
    "\n",
    "  def reset_hidden(self,device):\n",
    "    with torch.no_grad():\n",
    "      self.Linear_hidden1 = [nn.Linear(40,40).to(self.target_dev)]\n",
    "      self.Linear_hidden2 = [nn.Linear(40,40).to(self.target_dev)]\n",
    "      self.Linear_hidden3 = [nn.Linear(40,40).to(self.target_dev)]\n",
    "      self.Linear_hidden4 = [nn.Linear(40,40).to(self.target_dev)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "xwIbcOL2Q3zd"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm\n",
    "def activate_gpu(force_cpu=False): # check if gpu available\n",
    "    device = \"cpu\"\n",
    "    if not force_cpu:\n",
    "        if torch.cuda.is_available(): # for both Nvidia and AMD GPUs\n",
    "            device = 'cuda'\n",
    "            print('DEVICE = ', torch.cuda.get_device_name(0))\n",
    "        elif torch.backends.mps.is_available(): # for mac ARM chipset\n",
    "            device = 'mps'\n",
    "            print('DEVICE = ', \"mps\" )\n",
    "        else: # for cpu only\n",
    "            device = 'cpu'\n",
    "            print('DEVICE = ', 'CPU', \"blue\")\n",
    "    return device\n",
    "\n",
    "def cluster_training(train_X,train_Y,train_Y_emo,batch_size,device):\n",
    "  i = 0\n",
    "  j = 0\n",
    "  batch_X = []\n",
    "  batch_Y = []\n",
    "  batch_emo = []\n",
    "  while True:\n",
    "    found = False\n",
    "    sbx = []\n",
    "    sby = []\n",
    "    sbe = []\n",
    "    lx,ly,le = [], [], []\n",
    "    while i < len(train_X):\n",
    "      if j < len(train_X[i]) - 1:\n",
    "        if len(lx) >= batch_size:\n",
    "          sbx.append(lx.copy())\n",
    "          sby.append(ly.copy())\n",
    "          sbe.append(le.copy())\n",
    "          lx = []\n",
    "          ly = []\n",
    "          le = []\n",
    "        found = True\n",
    "        lx.append(train_X[i][j])\n",
    "        ly.append(train_Y[i][j])\n",
    "        le.append(train_Y_emo[i][j+1])\n",
    "      i += 1\n",
    "\n",
    "    if found == False:\n",
    "      break\n",
    "    batch_X.append(sbx.copy())\n",
    "    batch_Y.append(sby.copy())\n",
    "    batch_emo.append(sbe.copy())\n",
    "    j += 1\n",
    "    i = 0\n",
    "  return batch_X, batch_Y, batch_emo\n",
    "\n",
    "def optimize_batch(model,device,bX1,bY1,bEmo1,optimizer):\n",
    "  loss_function = nn.CrossEntropyLoss()\n",
    "  loss = 0\n",
    "  for bX, bY, bEmo in zip(bX1, bY1, bEmo1):\n",
    "    if len(bX) <= 1:\n",
    "      continue\n",
    "    utts = torch.stack(bX).to(device)\n",
    "    emos = torch.stack(bY).to(device)\n",
    "    next_emos = torch.stack(bEmo).to(device)\n",
    "    pred_tokens, pred_emotion = model.forward(utts,emos)\n",
    "    loss += loss_function(pred_emotion,next_emos)\n",
    "  if type(loss) in [int, float]:\n",
    "    return loss\n",
    "  loss.backward(retain_graph=True)\n",
    "  optimizer.step()\n",
    "  return loss.item()\n",
    "\n",
    "\n",
    "def train(model, epochs, device,train_X, train_Y, train_Y_emo,batch_size = 500):\n",
    "  optimizer = optim.Adam(model.parameters())\n",
    "  model.train()\n",
    "  model = model.to(device)\n",
    "  losses = []\n",
    "  for i in emotion_class.keys():\n",
    "    emotion_class[i] = emotion_class[i].to(device)\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    model.zero_grad()\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    x_axis = []\n",
    "    loss_batch = 0\n",
    "    model.current_weight = 0\n",
    "    optimizer.zero_grad()\n",
    "    model.zero_grad()\n",
    "    batch_X, batch_Y, batch_emo = cluster_training(train_X,train_Y,train_Y_emo,batch_size,device)\n",
    "    for bX1,bY1,bEmo1 in tqdm(zip(batch_X,batch_Y,batch_emo)):\n",
    "\n",
    "      loss_batch += optimize_batch(model,device,bX1,bY1,bEmo1,optimizer)\n",
    "      if epoch == 0:\n",
    "        with torch.no_grad():\n",
    "          model.update_text_w()\n",
    "          model.update_emotions_w()\n",
    "      model.current_weight += 1\n",
    "\n",
    "    loss_batch = loss_batch/(len(batch_X))\n",
    "    losses.append(loss_batch)\n",
    "    print(f\"loss: \",loss_batch)\n",
    "  return losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IMl6CqIu72Ze",
    "outputId": "0bd8bad3-4b36-4549-c1ad-6ff4e9c1bc72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE =  NVIDIA GeForce MX250\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = activate_gpu()\n",
    "model = SimpleModel(word_dim,word_dim,len(emotions),len(w2v.wv),device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "5435b388b35d4952af52b6d8bf9bb993",
      "54f66185cb2c44e083a93e72d759657b",
      "fb4ee56dd1944cedbf3903f033206ecb",
      "9f41d052137146588a4701d8545cd37d",
      "8e37de6d07c744a4a9440dbfaa3f50be",
      "00e4411e980b468a97fed6d83224a2e3",
      "7ac33bf0518f4c8f8dc34dfca33e4060",
      "48b54b743dba4fa8bcc2527b4dae5100",
      "5801b29a33f445908ce75ab6466a2597",
      "7adc4d42374e4b41bbdb1481e48c0166",
      "1e5587a016ad4f3185725f315464ad06"
     ]
    },
    "id": "6jmIaKWuHoAa",
    "outputId": "5698fee5-01dc-4a30-ff56-7fc05d707ed5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53619dc41a5e447b838c7a44f5206de7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  4.578382715042391\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8d55ca26ca54077a9c5739802d462a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  4.562260303163775\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c990a4ee310a464db974402e5e332448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  4.561104101529393\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91d66c86f22f4f6eb7407ce04369c1a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  4.561033028703897\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "704104b5d22f4f92b5be89f928c58433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  4.560989234886021\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72e68d8fd8e04a3f90bdc9574aff8841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  4.560960452328074\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81196f861a8640ef8628fa31db50e50b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  4.560942629303957\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3989bd5ef06f49c9a942097b68c8d6ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  4.560927997444578\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc8c0fd913a8400b974be92ac423af6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  4.560912996839365\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53961d9f710741239520d3545a97db21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  4.560902229399261\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x72d94d9e7c50>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 10\n",
    "losses = train(model,epochs,device,X_train1,Y_train1,Y_train_emo)\n",
    "plt.plot(np.arange(1,epochs+1),losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kHvIlbSp1hpF"
   },
   "source": [
    "# Descrition of the issues faced:\n",
    "\n",
    "It is not trivial of how to deal with the gradient flow in this case. Maybe by fixing the 2 matrix it would go better. Or just train the matrix with fixed weight. And update the weight not in the forward pass. but in the prediction. this way we can cache the weight and everytime we restart, we will be ok.\n",
    "\n",
    "I believe that, the issue of this approach specifically is updating directly the weights, and not, a hidden state, for instance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rkMtblC8Je0O",
    "outputId": "ed719a45-b47e-4471-ce2e-b8d9fd101447"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.6026026026026026\n",
      "The loss on the test set is:  1.5628195985540136\n",
      "precision:  0.6596596596596597\n",
      "The loss on the test set is:  1.5057625414969567\n"
     ]
    }
   ],
   "source": [
    "def compute_test_loss(model,X,Y,Y_emo,loss_fn,device):\n",
    "  model.eval()\n",
    "  losses = []\n",
    "  prec = 0\n",
    "  total = 0\n",
    "  for i in range(len(X)):\n",
    "    for k in range(len(X[i])):\n",
    "      X[i][k] = X[i][k].to(device)\n",
    "      Y[i][k] = Y[i][k].to(device)\n",
    "      Y_emo[i][k] = Y_emo[i][k].to(device)\n",
    "  for j in emotion_class.keys():\n",
    "    emotion_class[j] = emotion_class[j].to(device)\n",
    "  for seq_X, seq_Y, seq_emo in zip(X[:-1],Y[:-1],Y_emo[1:]):\n",
    "    loss = 0\n",
    "    pt,pe = model.predict_for_sequence(seq_X,seq_Y)\n",
    "    if pe == torch.argmax(seq_emo[-1]):\n",
    "      prec += 1\n",
    "    loss += loss_fn(emotion_class[pe],seq_emo[-1])\n",
    "    total +=1\n",
    "    losses.append(loss.item())\n",
    "  print(\"precision: \", prec/total)\n",
    "  print(\"The loss on the test set is: \", np.mean(losses))\n",
    "\n",
    "compute_test_loss(model,X_test1,Y_test1,Y_test_emo,nn.CrossEntropyLoss(),device)\n",
    "compute_test_loss(model,X_val1,Y_val1,Y_val_emo,nn.CrossEntropyLoss(),device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "wkAx-PPJdmWT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "pt_env",
   "language": "python",
   "name": "pt_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00e4411e980b468a97fed6d83224a2e3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e5587a016ad4f3185725f315464ad06": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "48b54b743dba4fa8bcc2527b4dae5100": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "5435b388b35d4952af52b6d8bf9bb993": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_54f66185cb2c44e083a93e72d759657b",
       "IPY_MODEL_fb4ee56dd1944cedbf3903f033206ecb",
       "IPY_MODEL_9f41d052137146588a4701d8545cd37d"
      ],
      "layout": "IPY_MODEL_8e37de6d07c744a4a9440dbfaa3f50be"
     }
    },
    "54f66185cb2c44e083a93e72d759657b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_00e4411e980b468a97fed6d83224a2e3",
      "placeholder": "",
      "style": "IPY_MODEL_7ac33bf0518f4c8f8dc34dfca33e4060",
      "value": ""
     }
    },
    "5801b29a33f445908ce75ab6466a2597": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7ac33bf0518f4c8f8dc34dfca33e4060": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7adc4d42374e4b41bbdb1481e48c0166": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8e37de6d07c744a4a9440dbfaa3f50be": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9f41d052137146588a4701d8545cd37d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7adc4d42374e4b41bbdb1481e48c0166",
      "placeholder": "",
      "style": "IPY_MODEL_1e5587a016ad4f3185725f315464ad06",
      "value": "7/?[00:17&lt;00:00,2.45s/it]"
     }
    },
    "fb4ee56dd1944cedbf3903f033206ecb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_48b54b743dba4fa8bcc2527b4dae5100",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5801b29a33f445908ce75ab6466a2597",
      "value": 1
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
