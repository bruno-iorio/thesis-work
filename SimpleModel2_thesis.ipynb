{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thH7IEDfz9EJ"
      },
      "source": [
        "\n",
        "# Explanation of the task:\n",
        "\n",
        "This is the classic Emotion Recognition Classification task. Given a conversation, involving 2 or more parties, for each message/utterance, we want to predict an emotion related to it.\n",
        "\n",
        "\n",
        "Consider the example:\n",
        "\n",
        "**Person A**: \"Hello! I am very happy\" (happiness)\n",
        "\n",
        "**Person B**: \"Why? I am very angry\"   (anger)\n",
        "\n",
        "## First model idea:\n",
        "- inputs: sequence of utterances, sequence of emotions.\n",
        "- For each: Linear Layers\n",
        "- Fusion model\n",
        "\n",
        "- Loss: cross-entropy\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahJqQ42nHjCY"
      },
      "source": [
        "# Preprocessing:\n",
        "\n",
        "Consider the each conversation as just a sequence of words:\n",
        "$$\n",
        "[[utt, utt, \\cdots], \\cdots ] \\longrightarrow [[word, word , \\cdots], \\cdots]\n",
        "$$\n",
        "\n",
        "In here, we add a separator token \"sep\". It will serve to indicate when a utteration is over, and another one starts. We also add a padding token at the end to ensure that all inputs have same dimention.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmXtaDwE1rk1",
        "outputId": "dba9072c-6537-4f64-cc35-d6730877bb12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.9.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.11/dist-packages (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement json (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for json\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "! pip install nltk\n",
        "! pip install torch\n",
        "! pip install pandas\n",
        "! pip install gensim\n",
        "! pip install datasets\n",
        "! pip install matplotlib\n",
        "! pip install tqdm\n",
        "! pip install torchinfo\n",
        "! pip install requests json\n",
        "# eventually include tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yKzjVDPZz8Pw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import gensim\n",
        "import json\n",
        "import requests\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "from datasets import load_dataset\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from collections import Counter\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzHR4n87uSwx",
        "outputId": "6cc87e42-9138-4098-dfef-98b30df41a8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-21 21:59:53--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 13.35.7.82, 13.35.7.50, 13.35.7.38, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|13.35.7.82|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 681808098 (650M) [application/zip]\n",
            "Saving to: ‘wiki-news-300d-1M.vec.zip’\n",
            "\n",
            "wiki-news-300d-1M.v 100%[===================>] 650.22M  62.0MB/s    in 12s     \n",
            "\n",
            "2025-01-21 22:00:05 (55.4 MB/s) - ‘wiki-news-300d-1M.vec.zip’ saved [681808098/681808098]\n",
            "\n",
            "Archive:  wiki-news-300d-1M.vec.zip\n",
            "replace wiki-news-300d-1M.vec? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ]
        }
      ],
      "source": [
        "! wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
        "! unzip wiki-news-300d-1M.vec.zip\n",
        "! rm wiki-news-300d-1M.vec.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "spEbLV4GunkW"
      },
      "outputs": [],
      "source": [
        "## taken from template\n",
        "encoder_model = gensim.models.KeyedVectors.load_word2vec_format(\"wiki-news-300d-1M.vec\", binary = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Dil129-UDo0t"
      },
      "outputs": [],
      "source": [
        "## We create the embeddings and find the vocab\n",
        "import copy\n",
        "unk_token, sep_token = '<unk>','<sep>'\n",
        "embedding_vectors = torch.from_numpy(encoder_model.vectors)\n",
        "pretrained_vocab = copy.deepcopy(encoder_model.index_to_key)\n",
        "pretrained_vocab[:0] = [unk_token,sep_token]\n",
        "\n",
        "stoi = {word: i for i, word in enumerate(pretrained_vocab)}\n",
        "itos = {i: word for i, word in enumerate(pretrained_vocab)}\n",
        "\n",
        "pretrained_embeddings = torch.cat((torch.ones(1,embedding_vectors.shape[1]),embedding_vectors))\n",
        "pretrained_embeddings = torch.cat((-torch.ones(1,embedding_vectors.shape[1]),embedding_vectors))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dByMWHT_Fu6S",
        "outputId": "8f5bff56-a9f8-4587-c48d-c6b8e900bd22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hello, I am a I robot!', 'I am greek'] becomes [13171, 2, 30, 783, 9, 30, 6871, 79, 1, 30, 783, 22504]\n",
            "[1, 2] becomes [1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2]\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import TweetTokenizer\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "max_size = 50\n",
        "## By using the template that was shared, we can process the inputs in a very similar way\n",
        "tok = TweetTokenizer()\n",
        "def tokenize_text_extend_emotions(text,emotion,stoi): ## utteration : string -> list of tokenized words : [int]\n",
        "  text = tok.tokenize(text)\n",
        "  text = [stoi[word] if word in stoi else stoi['<unk>'] for word in text]\n",
        "  return text, [emotion]*len(text)\n",
        "\n",
        "def concat_utt(dialog, emotions, stoi, max_size=max_size + 1): ## list of utterations : [string] -> list of list of tokenized words : [int]\n",
        "  tokenized_and_extended = [tokenize_text_extend_emotions(t,e,stoi) for t,e in zip(dialog,emotions)]\n",
        "  dialog = [i[0] for i in tokenized_and_extended]\n",
        "  emotions = [i[1] for i in tokenized_and_extended]\n",
        "  dialog_flat = []\n",
        "  emotions_extended = []\n",
        "  for i in range(len(dialog) - 1):\n",
        "    dialog[i].append(stoi[\"<sep>\"])\n",
        "    emotions[i].append(emotions[i][0])\n",
        "  for i in range(len(dialog)):\n",
        "    dialog_flat.extend(dialog[i])\n",
        "    emotions_extended.extend(emotions[i])\n",
        "  return dialog_flat,emotions_extended\n",
        "\n",
        "def preprocess_data(X,Y): ## list of lists of utterations : [[string]] -> list of lists of tokenized words : [[int]]\n",
        "  X_processed = []\n",
        "  Y_processed = []\n",
        "  for i in tqdm(range(len(X))):\n",
        "    X_processed.append(concat_utt(X[i],Y[i],stoi)[0])\n",
        "    Y_processed.append(concat_utt(X[i],Y[i],stoi)[1])\n",
        "  return X_processed, Y_processed\n",
        "\n",
        "def get_target(X,Y): ## generates the target values and input values\n",
        "  text_input = [i[:-1] for i in X]\n",
        "  text_target = [i[1:] for i in X]\n",
        "  emotion_input = [i[:-1] for i in Y]\n",
        "  emotion_target = [i[1:] for i in Y]\n",
        "  return text_input, text_target, emotion_input, emotion_target\n",
        "\n",
        "\n",
        "## Check the following example:\n",
        "dialog_example = [\"hello, I am a I robot!\",\"I am greek\"]\n",
        "emotions_example = [1,2] ## random emotions...\n",
        "\n",
        "flatten_dialog, flatten_emotions = concat_utt(dialog_example,emotions_example,stoi)\n",
        "print(f\"{dialog_example} becomes {flatten_dialog}\")\n",
        "print(f\"{emotions_example} becomes {flatten_emotions}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76MNsIfVHjCa"
      },
      "source": [
        "## DataLoader not implemented yet:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Fg_YM3ntHjCa"
      },
      "outputs": [],
      "source": [
        "## Modify this after changing the preprocessing.\n",
        "class DailyDialogDataset(Dataset):\n",
        "  def __init__(self, texts, emotions,target_texts,target_emotions):\n",
        "  # Dataset object for Daily Dialog dataset\n",
        "    self.texts = texts                     ## tokenized text\n",
        "    self.emotions = emotions               ## tokenized emotions\n",
        "    self.target_texts = target_texts       ## target text for loss computation\n",
        "    self.target_emotions = target_emotions ## target emotions for loss computation\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.texts)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    item = {\n",
        "                'texts': np.array(self.texts[idx]),\n",
        "             'emotions': np.array(self.emotions[idx]),\n",
        "         'target_texts': np.array(self.target_texts[idx]),\n",
        "      'target_emotions': np.array(self.target_emotions[idx])\n",
        "    }\n",
        "    return item\n",
        "class MeldDataset(Dataset):\n",
        "  def __init__(self, texts, emotions,target_texts,target_emotions):\n",
        "  # Dataset object for MELD dataset\n",
        "    self.texts = texts                     ## tokenized text\n",
        "    self.emotions = emotions               ## tokenized emotions\n",
        "    self.target_texts = target_texts       ## target text for loss computation\n",
        "    self.target_emotions = target_emotions ## target emotions for loss computation\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.texts)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    item = {\n",
        "                'texts': np.array(self.texts[idx]),\n",
        "             'emotions': np.array(self.emotions[idx]),\n",
        "         'target_texts': np.array(self.target_texts[idx]),\n",
        "      'target_emotions': np.array(self.target_emotions[idx])\n",
        "    }\n",
        "    return item\n",
        "class EmorynlpDataset(Dataset):\n",
        "  def __init__(self, texts, emotions,target_texts,target_emotions):\n",
        "    # Dataset object for EmoryNLP dataset\n",
        "    self.texts = texts                     ## tokenized text\n",
        "    self.emotions = emotions               ## tokenized emotions\n",
        "    self.target_texts = target_texts       ## target text for loss computation\n",
        "    self.target_emotions = target_emotions ## target emotions for loss computation\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.texts)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    item = {\n",
        "                 'texts': np.array(self.texts[idx]),\n",
        "              'emotions': np.array(self.emotions[idx]),\n",
        "          'target_texts': np.array(self.target_texts[idx]),\n",
        "      'target_emotions' : np.array(self.target_emotions[idx])\n",
        "    }\n",
        "    return item\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o85DNm0FXNeK"
      },
      "source": [
        "Here we will extract the data and process it:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://raw.githubusercontent.com/declare-lab/MELD/refs/heads/master/data/MELD/dev_sent_emo.csv\n",
        "! wget https://raw.githubusercontent.com/declare-lab/MELD/refs/heads/master/data/MELD/test_sent_emo.csv\n",
        "! wget https://raw.githubusercontent.com/declare-lab/MELD/refs/heads/master/data/MELD/train_sent_emo.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0PXNpYsGIc7",
        "outputId": "edcdc91b-51e4-4615-afc7-92a1822d22f2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-21 22:06:19--  https://raw.githubusercontent.com/declare-lab/MELD/refs/heads/master/data/MELD/dev_sent_emo.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 121640 (119K) [text/plain]\n",
            "Saving to: ‘dev_sent_emo.csv.1’\n",
            "\n",
            "dev_sent_emo.csv.1  100%[===================>] 118.79K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-01-21 22:06:19 (1.21 MB/s) - ‘dev_sent_emo.csv.1’ saved [121640/121640]\n",
            "\n",
            "--2025-01-21 22:06:19--  https://raw.githubusercontent.com/declare-lab/MELD/refs/heads/master/data/MELD/test_sent_emo.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 294526 (288K) [text/plain]\n",
            "Saving to: ‘test_sent_emo.csv.1’\n",
            "\n",
            "test_sent_emo.csv.1 100%[===================>] 287.62K  1.77MB/s    in 0.2s    \n",
            "\n",
            "2025-01-21 22:06:20 (1.77 MB/s) - ‘test_sent_emo.csv.1’ saved [294526/294526]\n",
            "\n",
            "--2025-01-21 22:06:21--  https://raw.githubusercontent.com/declare-lab/MELD/refs/heads/master/data/MELD/train_sent_emo.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1119290 (1.1M) [text/plain]\n",
            "Saving to: ‘train_sent_emo.csv.1’\n",
            "\n",
            "train_sent_emo.csv. 100%[===================>]   1.07M  4.81MB/s    in 0.2s    \n",
            "\n",
            "2025-01-21 22:06:21 (4.81 MB/s) - ‘train_sent_emo.csv.1’ saved [1119290/1119290]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KC_RQMGGXP7j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3091cf25-81ac-46e5-a78e-4cd90845e586"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function tqdm.__del__ at 0x7aa1a1601440>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tqdm/std.py\", line 1147, in __del__\n",
            "    def __del__(self):\n",
            "\n",
            "KeyboardInterrupt: \n"
          ]
        }
      ],
      "source": [
        "data_dd = load_dataset('daily_dialog') ## daily conversations\n",
        "data_meld_train = pd.read_csv('train_sent_emo.csv').drop(columns=['Sr No.','Speaker','Sentiment','Season','Episode','StartTime','EndTime'])\n",
        "data_meld_val = pd.read_csv('dev_sent_emo.csv').drop(columns=['Sr No.','Speaker','Sentiment','Season','Episode','StartTime','EndTime'])\n",
        "data_meld_test = pd.read_csv('test_sent_emo.csv').drop(columns=['Sr No.','Speaker','Sentiment','Season','Episode','StartTime','EndTime'])\n",
        "\n",
        "## For Daily Dialog:\n",
        "X_train_dd = data_dd['train']['dialog']\n",
        "Y_train_dd = data_dd['train']['emotion']\n",
        "X_test_dd = data_dd['test']['dialog']\n",
        "Y_test_dd = data_dd['test']['emotion']\n",
        "X_val_dd = data_dd['validation']['dialog']\n",
        "Y_val_dd = data_dd['validation']['emotion']\n",
        "\n",
        "## For MELD\n",
        "def change_Y(Y,lookup=None):\n",
        "  lookup = {} if lookup is None else lookup\n",
        "  k = 0\n",
        "  for i in range(len(Y)):\n",
        "    for j in range(len(Y[i])):\n",
        "      if Y[i][j] not in lookup:\n",
        "        lookup[Y[i][j]] = k\n",
        "        Y[i][j] = k\n",
        "        k += 1\n",
        "      else:\n",
        "        Y[i][j] = lookup[Y[i][j]]\n",
        "  return Y, lookup\n",
        "\n",
        "\n",
        "def parse_meld(df,lookup = None):\n",
        "  X, Y = {}, {}\n",
        "  for _, row in df.iterrows():\n",
        "    dialog_id = row['Dialogue_ID']\n",
        "    if dialog_id not in X:\n",
        "      X[dialog_id] = []\n",
        "      Y[dialog_id] = []\n",
        "    X[dialog_id].append(row['Utterance'])\n",
        "    Y[dialog_id].append(row['Emotion'])\n",
        "  X = list(X.values())\n",
        "  Y = list(Y.values())\n",
        "  Y,lookup = change_Y(Y,lookup)\n",
        "  return X, Y, lookup\n",
        "\n",
        "X_train_meld, Y_train_meld, lookup_meld = parse_meld(data_meld_train)\n",
        "X_test_meld, Y_test_meld, _ = parse_meld(data_meld_test,lookup_meld)\n",
        "X_val_meld, Y_val_meld, _ = parse_meld(data_meld_val,lookup_meld)\n",
        "\n",
        "\n",
        "## For EmoryNLP:\n",
        "def parse_seasons(seasons): ## annoying parsing\n",
        "  X = []\n",
        "  Y = []\n",
        "  for i in seasons:\n",
        "    for episode in seasons[i]['episodes']:\n",
        "      for scene in episode['scenes']:\n",
        "        try:\n",
        "          dialog = []\n",
        "          emotion = []\n",
        "          for utterance in scene['utterances']:\n",
        "            if utterance['transcript'] != '':\n",
        "              dialog.append(utterance['transcript'])\n",
        "              emotion.append(utterance['emotion'][0])\n",
        "          X.append(dialog)\n",
        "          Y.append(emotion)\n",
        "        except:\n",
        "          continue\n",
        "    Y,lookup = change_Y(Y)\n",
        "    return X, Y, lookup\n",
        "\n",
        "def parse_emory(): ## getting from the web\n",
        "  seasons = {}\n",
        "  for i in range(1,11):\n",
        "    s_id = '0' + str(i) if i < 10 else str(i)\n",
        "    json_file = f'https://raw.githubusercontent.com/emorynlp/character-mining/master/json/friends_season_{s_id}.json'\n",
        "    r = requests.get(json_file)\n",
        "    season = json.loads(r.text)\n",
        "    seasons[i] = season\n",
        "  return parse_seasons(seasons)\n",
        "\n",
        "X_emory, Y_emory, lookup_emory = parse_emory()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prtVZtnj-xVD"
      },
      "outputs": [],
      "source": [
        "# For Daily Dialog\n",
        "X_train_dd, Y_train_dd = preprocess_data(X_train_dd,Y_train_dd)\n",
        "X_train_dd,X_train_target_dd, Y_train_dd, Y_train_target_dd = get_target(X_train_dd,Y_train_dd)\n",
        "X_test_dd, Y_test_dd = preprocess_data(X_test_dd,Y_test_dd)\n",
        "X_test_dd,X_test_target_dd, Y_test_dd, Y_test_target_dd = get_target(X_test_dd,Y_test_dd)\n",
        "X_val_dd, Y_val_dd = preprocess_data(X_val_dd,Y_val_dd)\n",
        "X_val_dd, X_val_target_dd, Y_val_dd, Y_val_target_dd = get_target(X_val_dd,Y_val_dd)\n",
        "\n",
        "# For MELD\n",
        "X_train_meld, Y_train_meld = preprocess_data(X_train_meld,Y_train_meld)\n",
        "X_train_meld,X_train_target_meld, Y_train_meld, Y_train_target_meld = get_target(X_train_meld,Y_train_meld)\n",
        "X_test_meld, Y_test_meld = preprocess_data(X_test_meld,Y_test_meld)\n",
        "X_test_meld,X_test_target_meld, Y_test_meld, Y_test_target_meld = get_target(X_test_meld,Y_test_meld)\n",
        "X_val_meld, Y_val_meld = preprocess_data(X_val_meld,Y_val_meld)\n",
        "X_val_meld, X_val_target_meld, Y_val_meld, Y_val_target_meld = get_target(X_val_meld,Y_val_meld)\n",
        "\n",
        "## For EmoryNLP:\n",
        "X_emory, Y_emory = preprocess_data(X_emory,Y_emory)\n",
        "X_emory,X_target_emory, Y_emory, Y_target_emory = get_target(X_emory,Y_emory)\n",
        "\n",
        "## Just checking if nothing wrong happened\n",
        "\"\"\"\n",
        "for d, e in zip(X_train,Y_train):\n",
        "  assert(len(d) == len(e))\n",
        "for d, e in zip(X_test,Y_test):\n",
        "  assert(len(d) == len(e))\n",
        "for d, e in zip(X_val,Y_val):\n",
        "  assert(len(d) == len(e))\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJCwMdlcRGBL"
      },
      "outputs": [],
      "source": [
        "batch_size = 1 ## try with other values. 5 Might be too little!\n",
        "\n",
        "train_data_dd = DailyDialogDataset(X_train_dd,Y_train_dd,X_train_target_dd,Y_train_target_dd)\n",
        "test_data_dd = DailyDialogDataset(X_test_target_dd,Y_test_target_dd,X_test_target_dd,Y_test_target_dd)\n",
        "val_data_dd = DailyDialogDataset(X_val_target_dd,Y_val_target_dd,X_val_target_dd,Y_val_target_dd)\n",
        "\n",
        "train_data_meld = MeldDataset(X_train_meld,Y_train_meld,X_train_target_meld,Y_train_target_meld)\n",
        "test_data_meld = MeldDataset(X_test_meld,Y_test_meld,X_test_target_meld,Y_test_target_meld)\n",
        "val_data_meld = MeldDataset(X_val_meld,Y_val_meld,X_val_target_meld,Y_val_target_meld)\n",
        "\n",
        "data_emory = EmorynlpDataset(X_emory,Y_emory,X_target_emory,Y_target_emory)\n",
        "train_data_emory, test_data_emory, val_data_emory = random_split(data_emory,[118,50,50]) ## len(data_emory) = 218 = 118 + 50 + 50\n",
        "\n",
        "train_loader_dd = DataLoader(train_data_dd, batch_size=batch_size,shuffle = True,)\n",
        "test_loader_dd = DataLoader(test_data_dd, batch_size=batch_size,shuffle = True)\n",
        "val_loader_dd = DataLoader(val_data_dd, batch_size=batch_size, shuffle = True)\n",
        "\n",
        "train_loader_meld = DataLoader(train_data_meld, batch_size=batch_size,shuffle = True,)\n",
        "test_loader_meld = DataLoader(test_data_meld, batch_size=batch_size,shuffle = True)\n",
        "val_loader_meld = DataLoader(val_data_meld, batch_size=batch_size, shuffle = True)\n",
        "\n",
        "train_loader_emory = DataLoader(train_data_emory, batch_size=batch_size,shuffle = True)\n",
        "test_loader_emory = DataLoader(test_data_emory, batch_size=batch_size,shuffle = True)\n",
        "val_loader_emory = DataLoader(val_data_emory, batch_size=batch_size, shuffle = True)\n",
        "\n",
        "## Example:\n",
        "\n",
        "val_data_emory[2] ## note that padding = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbNZKfP-yVrL"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pyBr61UXulR"
      },
      "source": [
        "# The model:\n",
        "## archtecture\n",
        "- 2 input channels: word encoding, emotion encoding\n",
        "- dinamically updated weights: $w_1, w_2 = w1 + w2, w1$ (Not implemented yet)\n",
        "### For each channel:\n",
        "   - 3 sequential Linear layers\n",
        "- fusion linear layer through concatenation\n",
        "- 2 output channels which contain a linear layer each\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "F5G-cFE81iXV"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "class SimpleModel(nn.Module):\n",
        "  def __init__(self, emo_dim, n_emotion, n_vocab):\n",
        "    super(SimpleModel,self).__init__()\n",
        "    ## word_dim = 300\n",
        "    self.embedding_layer_text = nn.Embedding.from_pretrained(pretrained_embeddings, freeze=True)\n",
        "    self.embedding_layer_emotion = nn.Embedding(n_emotion, emo_dim)\n",
        "    ## Channel for utterances/words:\n",
        "    self.Linear_utt1 = nn.Linear(300,80)\n",
        "    self.Linear_utt2 = nn.Linear(80,80)\n",
        "    self.Linear_utt3 = nn.Linear(80,80)\n",
        "\n",
        "    ## Channel for emotions:\n",
        "    self.Linear_emo1 = nn.Linear(emo_dim,80)\n",
        "    self.Linear_emo2 = nn.Linear(80,80)\n",
        "    self.Linear_emo3 = nn.Linear(80,80)\n",
        "    # self.Linear_emo3.requires_grad = False\n",
        "\n",
        "    ## fusion by concatenation and Linear layer:\n",
        "    self.Linear_fus = nn.Linear(160,300)\n",
        "\n",
        "    ## We concatenate and do linear again (2 different concatenations)\n",
        "    self.Linear_utt_final1 = nn.Linear(380, 180)\n",
        "    self.Linear_utt_final2 = nn.Linear(180, 90)\n",
        "    self.Linear_utt_final3 = nn.Linear(90, 15)\n",
        "    self.Linear_utt_final = nn.Linear(15, n_vocab)\n",
        "\n",
        "\n",
        "    self.Linear_emo_final = nn.Linear(380, n_emotion)\n",
        "\n",
        "    self.softmax = nn.Softmax(dim=0)\n",
        "\n",
        "  def init_hidden(self):\n",
        "    pass # see later how to init this\n",
        "\n",
        "  def forward(self, text, emotion, hidden):\n",
        "    with torch.no_grad():\n",
        "      text = self.embedding_layer_text(text)\n",
        "    text = self.Linear_utt1(text)\n",
        "    text = self.Linear_utt2(text)\n",
        "    text = self.Linear_utt3(text)\n",
        "\n",
        "    emotion = self.embedding_layer_emotion(emotion)\n",
        "    emotion = self.Linear_emo1(emotion)\n",
        "    emotion = self.Linear_emo2(emotion)\n",
        "    emotion = self.Linear_emo3(emotion)\n",
        "\n",
        "    hidden = hidden +  emotion*0.7 + text*0.3\n",
        "    z = torch.cat((text,emotion),-1)\n",
        "    z = self.Linear_fus(z)\n",
        "\n",
        "    text = torch.cat((z,text),-1)\n",
        "    text = self.Linear_utt_final1(text)\n",
        "    text = self.Linear_utt_final2(text)\n",
        "    text = self.Linear_utt_final3(text)\n",
        "    text = self.Linear_utt_final(text)\n",
        "    text = self.softmax(text)\n",
        "    emotion = torch.cat((z,hidden),-1)\n",
        "    emotion = self.Linear_emo_final(emotion)\n",
        "    emotion = self.softmax(emotion)\n",
        "\n",
        "    return text, emotion, hidden\n",
        "    #return emotion\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "xwIbcOL2Q3zd"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "from tqdm.notebook import tqdm\n",
        "def activate_gpu(force_cpu=False): # check if gpu available ; code taken from template\n",
        "    device = \"cpu\"\n",
        "    if not force_cpu:\n",
        "        if torch.cuda.is_available(): # for both Nvidia and AMD GPUs\n",
        "            device = 'cuda'\n",
        "            print('DEVICE = ', torch.cuda.get_device_name(0))\n",
        "        elif torch.backends.mps.is_available(): # for mac ARM chipset\n",
        "            device = 'mps'\n",
        "            print('DEVICE = ', \"mps\" )\n",
        "        else: # for cpu only\n",
        "            device = 'cpu'\n",
        "            print('DEVICE = ', 'CPU', \"blue\")\n",
        "    return device\n",
        "\n",
        "## train functions\n",
        "\n",
        "def train_batch(model, batch, optimizer,lr):\n",
        "  loss = 0\n",
        "  loss_fn = nn.CrossEntropyLoss()\n",
        "  hidden_state = [torch.zeros(80, requires_grad=True).to(device)]\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  for t in range(len(batch['texts'])):\n",
        "    inp_token = batch['texts'][t]\n",
        "    inp_emotion = batch['emotions'][t]\n",
        "    target_token = batch['target_texts'][t]\n",
        "    target_emotion = batch['target_emotions'][t]\n",
        "\n",
        "    pt, pe, hidden = model.forward(inp_token,inp_emotion,hidden_state[-1])\n",
        "    hidden_state.append(hidden)\n",
        "    loss1 = loss_fn(pt,target_token) + loss_fn(pe,target_emotion)\n",
        "    loss += loss1\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  return loss.item()/len(batch['texts']) ## average\n",
        "\n",
        "def train(model, train_loader, epochs, device):\n",
        "  optimizer = optim.Adam(model.parameters())\n",
        "  loss_fn = nn.CrossEntropyLoss()\n",
        "  model.train()\n",
        "  model = model.to(device)\n",
        "  loss_to_plot = []\n",
        "  lr = 0.01\n",
        "  for epoch in range(epochs):\n",
        "    losses = []\n",
        "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "    for it, batch in tqdm(enumerate(train_loader),total = train_loader.__len__()):\n",
        "      batch = {'texts': torch.from_numpy(batch['texts']).to(device),\n",
        "               'emotions': torch.from_numpy(batch['emotions']).to(device),\n",
        "               'target_texts': torch.from_numpy(batch['target_texts']).view(-1).to(device), ## reshape is necessary to compare predictions\n",
        "               'target_emotions': torch.from_numpy(batch['target_emotions']).view(-1).to(device)\n",
        "      }\n",
        "      if lr % 20 == 0:\n",
        "        lr /= 10\n",
        "      losses.append(train_batch(model, batch, optimizer,lr))\n",
        "    loss_to_plot.append(sum(losses)/len(losses))\n",
        "    print(f\"loss: \",loss_to_plot[-1])\n",
        "  return loss_to_plot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMl6CqIu72Ze",
        "outputId": "1b96ece6-9ff4-4abe-8c6a-9b04d2f2e859"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEVICE =  CPU blue\n",
            "cpu\n",
            "=================================================================\n",
            "Layer (type:depth-idx)                   Param #\n",
            "=================================================================\n",
            "SimpleModel                              --\n",
            "├─Embedding: 1-1                         (299,998,500)\n",
            "├─Embedding: 1-2                         210\n",
            "├─Linear: 1-3                            24,080\n",
            "├─Linear: 1-4                            6,480\n",
            "├─Linear: 1-5                            6,480\n",
            "├─Linear: 1-6                            2,480\n",
            "├─Linear: 1-7                            6,480\n",
            "├─Linear: 1-8                            6,480\n",
            "├─Linear: 1-9                            48,300\n",
            "├─Linear: 1-10                           68,580\n",
            "├─Linear: 1-11                           16,290\n",
            "├─Linear: 1-12                           1,365\n",
            "├─Linear: 1-13                           15,999,936\n",
            "├─Linear: 1-14                           2,667\n",
            "├─Softmax: 1-15                          --\n",
            "=================================================================\n",
            "Total params: 316,188,328\n",
            "Trainable params: 16,189,828\n",
            "Non-trainable params: 299,998,500\n",
            "=================================================================\n"
          ]
        }
      ],
      "source": [
        "from torchinfo import summary\n",
        "\n",
        "## Setting some hyper parameters:\n",
        "device = activate_gpu()\n",
        "emotion_dim = 30\n",
        "n_emotions = 7\n",
        "n_words = len(stoi)\n",
        "\n",
        "model = SimpleModel(emotion_dim,n_emotions,n_words)\n",
        "print(device)\n",
        "print(summary(model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423,
          "referenced_widgets": [
            "d9af4123093d4cb28feb5d1d9af04c59",
            "c27717b37b13427292c4e4fec9eaa97a",
            "e157fe782dd541b29f6496e9b9f5c39c",
            "9774b6b579a545d9b60542e9b77b28b9",
            "327ba5390ad84f9aaa1bdeca987ee244",
            "a80c44362619484bbf54a67a5082c218",
            "c2e8bea8d3e2442fa164ee50c8581b56",
            "054f5d18fdcd4fc6a08e07387e0c837e",
            "bec9335c370146ce9263a6a4b2476ebb",
            "f8e5547df3d241e89562f7c4f61d66d8",
            "cd411ed1f3404d34acdabcf7e2ded8cd"
          ]
        },
        "id": "6jmIaKWuHoAa",
        "outputId": "d6061bb7-1ed0-4ccd-c5c2-42348344e546"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/118 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d9af4123093d4cb28feb5d1d9af04c59"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "Target 7 is out of bounds.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-4414cd47e3ea>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m## training in the cpu with the loss for the tokens excrutiatingly slow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m## It becomes faster when we train with only the loss for the emotions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_emory\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m## Somewhat of a problem: Since we have padding for the emotions also,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-344e85b28828>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, epochs, device)\u001b[0m\n\u001b[1;32m     55\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m20\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mlr\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m       \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0mloss_to_plot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"loss: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_to_plot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-344e85b28828>\u001b[0m in \u001b[0;36mtrain_batch\u001b[0;34m(model, batch, optimizer, lr)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minp_emotion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mhidden_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mloss1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_token\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_emotion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m   \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1292\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1293\u001b[0;31m         return F.cross_entropy(\n\u001b[0m\u001b[1;32m   1294\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m             \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3477\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3479\u001b[0;31m     return torch._C._nn.cross_entropy_loss(\n\u001b[0m\u001b[1;32m   3480\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3481\u001b[0m         \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: Target 7 is out of bounds."
          ]
        }
      ],
      "source": [
        "epochs = 7\n",
        "\n",
        "# Do later : increase batch size!\n",
        "## training in the cpu with the loss for the tokens excrutiatingly slow\n",
        "## It becomes faster when we train with only the loss for the emotions\n",
        "losses = train(model, train_data_emory , epochs, device)\n",
        "\n",
        "## Somewhat of a problem: Since we have padding for the emotions also,\n",
        "## it quite affects the predictions...\n",
        "plt.plot(np.arange(1,epochs+1),losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHvIlbSp1hpF"
      },
      "source": [
        "# Descrition of the issues faced:\n",
        "\n",
        "It is not trivial of how to deal with the gradient flow in this case. Maybe by fixing the 2 matrix it would go better. Or just train the matrix with fixed weight. And update the weight not in the forward pass. but in the prediction. this way we can cache the weight and everytime we restart, we will be ok.\n",
        "\n",
        "I believe that, the issue of this approach specifically is updating directly the weights, and not, a hidden state, for instance.\n",
        "\n",
        "# Problem with Daily Dialog:\n",
        "By plotting the frequency of each emotion, we notice that the dataset is truly not diversified. It has essentially only 2 emotions. This is not ideal, because the models will most likely overfit into predicting those 2 emotions..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "rkMtblC8Je0O"
      },
      "outputs": [],
      "source": [
        "def compute_test_loss(model,loss_fn,data_loader,device):\n",
        "  model.eval()\n",
        "  losses = []\n",
        "  accs = []\n",
        "  preds = [] ## predictions will be here\n",
        "  prec = 0\n",
        "  trues = [] ## true values will be here\n",
        "  for it,batch in tqdm(enumerate(data_loader),total=data_loader.__len__()):\n",
        "    batch = {'texts' : batch['texts'].view(-1).to(device),\n",
        "             'emotions': batch['emotions'].view(-1).to(device),\n",
        "             'target_texts': batch['target_texts'].view(-1).to(device),\n",
        "             'target_emotions': batch['target_emotions'].view(-1).to(device)}\n",
        "    hidden = torch.zeros(80, requires_grad=True).to(device)\n",
        "    for t in range(len(batch['texts'])):\n",
        "      inp_token = batch['texts'][t]\n",
        "      inp_emotion = batch['emotions'][t]\n",
        "      target_token = batch['target_texts'][t]\n",
        "      target_emotion = batch['target_emotions'][t]\n",
        "      _ , pe, hidden = model.forward(inp_token,inp_emotion,hidden)\n",
        "      loss1 = loss_fn(pe,target_emotion)\n",
        "      pe = torch.argmax(pe)\n",
        "      preds.append(pe.item())\n",
        "      trues.append(target_emotion.item())\n",
        "      if pe == target_emotion:\n",
        "        accs.append(1)\n",
        "      else:\n",
        "        accs.append(0)\n",
        "      losses.append(loss1.item())\n",
        "\n",
        "  print(\"average loss: \", sum(losses)/len(losses))\n",
        "  print(\"average acc: \", sum(accs)/len(accs))\n",
        "  return trues, preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "gE5S28C93TIN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "e6d08a02b82d4c6fb0af0fe3b7c533b1",
            "72f9e3086d924a80bbf39b38c3bfe587",
            "c7ae3a19231c490587aa4c361b3a41ba",
            "95d2e4ffcaf14290af723c28b619c053",
            "21b6fc7ff6e745fa90286f35e368506b",
            "9d263e6cfafc4073842071d3ee1e734c",
            "ab49868886bf4a63933cafd216e12316",
            "607e73db447740dab6be66d1c424f6c8",
            "6976be2687404914803a0d6ac75edec6",
            "c400bd4ae829441a9507c5f55c4b2153",
            "a4734df07e7b497591a630fd1f941b6d"
          ]
        },
        "outputId": "058ca805-9941-431f-9ddb-701132fb1a01"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6d08a02b82d4c6fb0af0fe3b7c533b1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average loss:  1.7098870263946102\n",
            "average acc:  0.5629331544824503\n"
          ]
        }
      ],
      "source": [
        "trues, preds = compute_test_loss(model,nn.CrossEntropyLoss(),test_loader_emory,device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-z_t9a34i5uN",
        "outputId": "3a96a218-3451-49b7-c83a-fe5ccb39cffd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.00      0.00      0.00       777\n",
            "           2       0.70      0.71      0.70      3706\n",
            "           3       0.62      0.67      0.65      1772\n",
            "           4       0.37      0.79      0.51      1551\n",
            "           5       0.00      0.00      0.00       468\n",
            "           6       0.00      0.00      0.00       234\n",
            "           7       0.00      0.00      0.00       438\n",
            "\n",
            "    accuracy                           0.56      8946\n",
            "   macro avg       0.24      0.31      0.27      8946\n",
            "weighted avg       0.48      0.56      0.51      8946\n",
            "\n",
            "[[   0  332   90  355    0    0    0]\n",
            " [   0 2615  360  731    0    0    0]\n",
            " [   0  181 1196  395    0    0    0]\n",
            " [   0  219  107 1225    0    0    0]\n",
            " [   0  240   23  205    0    0    0]\n",
            " [   0   58   99   77    0    0    0]\n",
            " [   0  105   52  281    0    0    0]]\n",
            "[5, 5, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
            "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "names = [f'{i}' for i in range(1,8)]\n",
        "print(classification_report(np.array(trues).flatten(), np.array(preds).flatten(), target_names=names))\n",
        "print(confusion_matrix(trues,preds))\n",
        "\n",
        "## to visually see how it compares:\n",
        "print(trues[:200])\n",
        "print(preds[:200])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkAx-PPJdmWT"
      },
      "outputs": [],
      "source": [
        "## finish later:\n",
        "\n",
        "def eval_sentence(model, sentence, encoded_sentence, emotions, device):\n",
        "  model.eval()\n",
        "  for i in range(len(sentence) - 1):\n",
        "    pe, _ = model.forward(encoded_sentence[i].to(device),emotions[i].to(device))\n",
        "    t = torch.max(pe,1)\n",
        "    print(f\"word:{sentence[i+1]}; predicted_emotion: {t} ; target_emotion: {emotions[i+1]}\")\n",
        "\n",
        "# eval_sentence(model,sentence,encod,emot,device)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d9af4123093d4cb28feb5d1d9af04c59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c27717b37b13427292c4e4fec9eaa97a",
              "IPY_MODEL_e157fe782dd541b29f6496e9b9f5c39c",
              "IPY_MODEL_9774b6b579a545d9b60542e9b77b28b9"
            ],
            "layout": "IPY_MODEL_327ba5390ad84f9aaa1bdeca987ee244"
          }
        },
        "c27717b37b13427292c4e4fec9eaa97a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a80c44362619484bbf54a67a5082c218",
            "placeholder": "​",
            "style": "IPY_MODEL_c2e8bea8d3e2442fa164ee50c8581b56",
            "value": "  2%"
          }
        },
        "e157fe782dd541b29f6496e9b9f5c39c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_054f5d18fdcd4fc6a08e07387e0c837e",
            "max": 118,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bec9335c370146ce9263a6a4b2476ebb",
            "value": 2
          }
        },
        "9774b6b579a545d9b60542e9b77b28b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8e5547df3d241e89562f7c4f61d66d8",
            "placeholder": "​",
            "style": "IPY_MODEL_cd411ed1f3404d34acdabcf7e2ded8cd",
            "value": " 2/118 [00:38&lt;34:19, 17.76s/it]"
          }
        },
        "327ba5390ad84f9aaa1bdeca987ee244": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a80c44362619484bbf54a67a5082c218": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2e8bea8d3e2442fa164ee50c8581b56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "054f5d18fdcd4fc6a08e07387e0c837e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bec9335c370146ce9263a6a4b2476ebb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f8e5547df3d241e89562f7c4f61d66d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd411ed1f3404d34acdabcf7e2ded8cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6d08a02b82d4c6fb0af0fe3b7c533b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_72f9e3086d924a80bbf39b38c3bfe587",
              "IPY_MODEL_c7ae3a19231c490587aa4c361b3a41ba",
              "IPY_MODEL_95d2e4ffcaf14290af723c28b619c053"
            ],
            "layout": "IPY_MODEL_21b6fc7ff6e745fa90286f35e368506b"
          }
        },
        "72f9e3086d924a80bbf39b38c3bfe587": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d263e6cfafc4073842071d3ee1e734c",
            "placeholder": "​",
            "style": "IPY_MODEL_ab49868886bf4a63933cafd216e12316",
            "value": "100%"
          }
        },
        "c7ae3a19231c490587aa4c361b3a41ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_607e73db447740dab6be66d1c424f6c8",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6976be2687404914803a0d6ac75edec6",
            "value": 50
          }
        },
        "95d2e4ffcaf14290af723c28b619c053": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c400bd4ae829441a9507c5f55c4b2153",
            "placeholder": "​",
            "style": "IPY_MODEL_a4734df07e7b497591a630fd1f941b6d",
            "value": " 50/50 [02:13&lt;00:00,  3.10s/it]"
          }
        },
        "21b6fc7ff6e745fa90286f35e368506b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d263e6cfafc4073842071d3ee1e734c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab49868886bf4a63933cafd216e12316": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "607e73db447740dab6be66d1c424f6c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6976be2687404914803a0d6ac75edec6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c400bd4ae829441a9507c5f55c4b2153": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4734df07e7b497591a630fd1f941b6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}